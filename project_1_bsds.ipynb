{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3647abcb",
   "metadata": {},
   "source": [
    "## Project 1 (Due 2/17)\n",
    "\n",
    "The goal of the first project is to do some wrangling, EDA, and visualization, and generate sequences of values. We will focus on:\n",
    "\n",
    "- CDC National Health and Nutritional Examination Survey (NHANES, 1999-2000): https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx?BeginYear=1999\n",
    "- CDC Linked Mortality File (LMF, 1999-2000): https://www.cdc.gov/nchs/data-linkage/mortality-public.htm\n",
    "\n",
    "NHANES is a rich panel dataset on health and behavior, collected bi-yearly from around 1999 to now. We will focus on the 1999 wave, because that has the largest follow-up window, providing us with the richest mortality data. The mortality data is provided by the CDC Linked Mortality File. \n",
    "\n",
    "The purpose of the project is to use $k$-NN to predict who dies (hard or soft classification) and how long they live (regression).\n",
    "\n",
    "### Day 1: Wrangling and EDA (40/100 pts)\n",
    "\n",
    "First, go to the NHANES and LMF web sites and familiarize yourself with the data sources. Download codebooks. Think about what resources are available. The CDC Linked Mortality File is somewhat of a pain to work with, so I have pre-cleaned it for you. It is available at httts://github.com/ds4e/undergraduate_ml_assignments in the data folder, as `lmf_parsed.cav`. From the CDC LMF web page, get the SAS program to load the data; it is the real codebook.\n",
    "\n",
    "Second, download the demographic data for the 1999--2000 wave from the NHANES page. You can use the following code chunk to merge the LMF and DEMO data:\n",
    "\n",
    "``` python\n",
    "import pandas as pd\n",
    "mdf = pd.read_csv('lmf_parsed.csv') # Load mortality file\n",
    "print( mdf.head() )\n",
    "gdf = pd.read_sas(\"DEMO.xpt\", format=\"xport\") # Load demographics file\n",
    "print( gdf.head() )\n",
    "df = gdf.merge(mdf, on=\"SEQN\", how=\"inner\") # Merge mortality and demographics on SEQN variable\n",
    "```\n",
    "\n",
    "Third, the variables `ELIGSTAT`, `MORTSTAT`, `PERMTH_INT`, and `RIDAGEEX` are particularly important. Look them up in the documentation and clearly describe them. (5/100 pts.)\n",
    "\n",
    "Second, the goal of the project is to use whatever demographic, behavioral, and health data you like to predict mortality (`MORTSTAT`) and life expectancy (`PERMTH_INT`). Go to the NHANES 1999--2000 web page and select your data and download it. Clearly explain your rationale for selecting these data. Use `.merge` to combine your data into one complete dataframe. Document missing values. (5/100 pts)\n",
    "\n",
    "Third, do basic EDA and visualization of the key variables. Are any important variables skewed? Are there outliers? How correlated are pairs of variables? Do pairs of categorical variables exhibit interesting patterns in contingency tables? Provide a clear discussion and examination of the data and the variables you are interested in using. (20/100 pts)\n",
    "\n",
    "\n",
    "### Day 2: $k$-NN classification/regression, write-up (50/100 pts)\n",
    "\n",
    "Submit a notebook that clearly addresses the following, using code and markdown chunks:\n",
    "\n",
    "1. Describe the data, particularly what an observation is and whether there are any missing data that might impact your analysis. Who collected the data and why? What known limitations are there to analysis? (10/100 pts)\n",
    "2. Describe the variables you selected to predict mortality and life expectancy, and the rationale behind them. Analyze your variables using describe tables, kernel densities, scatter plots, and conditional kernel densities. Are there any patterns of interest to notice? (10/100 pts)\n",
    "3. Using your variables to predict mortality using a $k$-Nearest Neighbor Classifier. Analyze its performance and explain clearly how you select $k$. (10/100 pts)\n",
    "4. Using your variables to predict life expectancy using a $k$-Nearest Neighbor Regressor. Analyze its performance and explain clearly how you select $k$. (10/100 pts)\n",
    "5. Describe how your model could be used for health interventions based on patient characteristics. Are there any limitations or risks to consider? (10/100 pts)\n",
    "\n",
    "## Submission (10/100 pts)\n",
    "\n",
    "Submit your work in a well-organized GitHub repo, where the code is appropriately commented and all members of the group have made significant contributions to the commit history. (10/100 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336aea1",
   "metadata": {},
   "source": [
    "Submission: Day 1 - First we begin with loading the two datasets (DEMO.xpt and linked_mortality_file_1999_2000.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4fb1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mortality file: (9965, 8)\n",
      "   SEQN  ELIGSTAT  MORTSTAT  UCOD_LEADING  DIABETES  HYPERTEN  PERMTH_INT  \\\n",
      "0     1         2       NaN           NaN       NaN       NaN         NaN   \n",
      "1     2         1       1.0           6.0       0.0       0.0       177.0   \n",
      "2     3         2       NaN           NaN       NaN       NaN         NaN   \n",
      "3     4         2       NaN           NaN       NaN       NaN         NaN   \n",
      "4     5         1       0.0           NaN       NaN       NaN       244.0   \n",
      "\n",
      "   PERMTH_EXM  \n",
      "0         NaN  \n",
      "1       177.0  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4       244.0  \n",
      "Demo file: (9965, 144)\n",
      "   SEQN  SDDSRVYR  RIDSTATR  RIDEXMON  RIAGENDR  RIDAGEYR  RIDAGEMN  RIDAGEEX  \\\n",
      "0   1.0       1.0       2.0       2.0       2.0       2.0      29.0      31.0   \n",
      "1   2.0       1.0       2.0       2.0       1.0      77.0     926.0     926.0   \n",
      "2   3.0       1.0       2.0       1.0       2.0      10.0     125.0     126.0   \n",
      "3   4.0       1.0       2.0       2.0       1.0       1.0      22.0      23.0   \n",
      "4   5.0       1.0       2.0       2.0       1.0      49.0     597.0     597.0   \n",
      "\n",
      "   RIDRETH1  RIDRETH2  ...      WTIREP43      WTIREP44      WTIREP45  \\\n",
      "0       4.0       2.0  ...  10094.017100   9912.461855   9727.078709   \n",
      "1       3.0       1.0  ...  27186.728682  27324.345051  28099.663528   \n",
      "2       3.0       1.0  ...  43993.193099  44075.386428  46642.563799   \n",
      "3       4.0       2.0  ...  10702.307249  10531.444441  10346.119327   \n",
      "4       3.0       1.0  ...  93164.782430  92119.608772  95388.490406   \n",
      "\n",
      "       WTIREP46      WTIREP47      WTIREP48      WTIREP49      WTIREP50  \\\n",
      "0  10041.524113  9.953956e+03   9857.381983   9865.152486  10327.992682   \n",
      "1  27757.066921  2.804929e+04  26716.602006  26877.704909  27268.025234   \n",
      "2  44967.681579  4.457248e+04  44087.945688  44831.370881  44480.987235   \n",
      "3  10636.063039  5.397605e-79  10533.108939  10654.749584  10851.024385   \n",
      "4  94131.383538  9.529781e+04  91325.082461  91640.586117  92817.926915   \n",
      "\n",
      "       WTIREP51      WTIREP52  \n",
      "0   9809.165049  10323.315747  \n",
      "1  27406.383620  26984.812909  \n",
      "2  45389.112766  43781.905637  \n",
      "3  10564.981435  11012.529729  \n",
      "4  94282.855382  91993.251203  \n",
      "\n",
      "[5 rows x 144 columns]\n",
      "Merged: (9965, 151)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>RIDSTATR</th>\n",
       "      <th>RIDEXMON</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDAGEMN</th>\n",
       "      <th>RIDAGEEX</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDRETH2</th>\n",
       "      <th>...</th>\n",
       "      <th>WTIREP50</th>\n",
       "      <th>WTIREP51</th>\n",
       "      <th>WTIREP52</th>\n",
       "      <th>ELIGSTAT</th>\n",
       "      <th>MORTSTAT</th>\n",
       "      <th>UCOD_LEADING</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>HYPERTEN</th>\n",
       "      <th>PERMTH_INT</th>\n",
       "      <th>PERMTH_EXM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10327.992682</td>\n",
       "      <td>9809.165049</td>\n",
       "      <td>10323.315747</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27268.025234</td>\n",
       "      <td>27406.383620</td>\n",
       "      <td>26984.812909</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44480.987235</td>\n",
       "      <td>45389.112766</td>\n",
       "      <td>43781.905637</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10851.024385</td>\n",
       "      <td>10564.981435</td>\n",
       "      <td>11012.529729</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92817.926915</td>\n",
       "      <td>94282.855382</td>\n",
       "      <td>91993.251203</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>244.0</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQN  SDDSRVYR  RIDSTATR  RIDEXMON  RIAGENDR  RIDAGEYR  RIDAGEMN  RIDAGEEX  \\\n",
       "0   1.0       1.0       2.0       2.0       2.0       2.0      29.0      31.0   \n",
       "1   2.0       1.0       2.0       2.0       1.0      77.0     926.0     926.0   \n",
       "2   3.0       1.0       2.0       1.0       2.0      10.0     125.0     126.0   \n",
       "3   4.0       1.0       2.0       2.0       1.0       1.0      22.0      23.0   \n",
       "4   5.0       1.0       2.0       2.0       1.0      49.0     597.0     597.0   \n",
       "\n",
       "   RIDRETH1  RIDRETH2  ...      WTIREP50      WTIREP51      WTIREP52  \\\n",
       "0       4.0       2.0  ...  10327.992682   9809.165049  10323.315747   \n",
       "1       3.0       1.0  ...  27268.025234  27406.383620  26984.812909   \n",
       "2       3.0       1.0  ...  44480.987235  45389.112766  43781.905637   \n",
       "3       4.0       2.0  ...  10851.024385  10564.981435  11012.529729   \n",
       "4       3.0       1.0  ...  92817.926915  94282.855382  91993.251203   \n",
       "\n",
       "   ELIGSTAT  MORTSTAT  UCOD_LEADING  DIABETES  HYPERTEN  PERMTH_INT  \\\n",
       "0         2       NaN           NaN       NaN       NaN         NaN   \n",
       "1         1       1.0           6.0       0.0       0.0       177.0   \n",
       "2         2       NaN           NaN       NaN       NaN         NaN   \n",
       "3         2       NaN           NaN       NaN       NaN         NaN   \n",
       "4         1       0.0           NaN       NaN       NaN       244.0   \n",
       "\n",
       "   PERMTH_EXM  \n",
       "0         NaN  \n",
       "1       177.0  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4       244.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load linked mortality file and the DEMO.xpt file\n",
    "mdf = pd.read_csv(\"data/linked_mortality_file_1999_2000.csv\")\n",
    "print(\"Mortality file:\", mdf.shape)\n",
    "print(mdf.head())\n",
    "gdf = pd.read_sas(\"data/DEMO.xpt\", format=\"xport\")\n",
    "print(\"Demo file:\", gdf.shape)\n",
    "print(gdf.head())\n",
    "# Merge\n",
    "df = gdf.merge(mdf, on=\"SEQN\", how=\"inner\")\n",
    "print(\"Merged:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081ffe8",
   "metadata": {},
   "source": [
    "1. `ELIGSTAT`:This variable tells you whether a survey participant was eligible to be linked to mortality (death) records in the National Death Index (NDI):\n",
    "\n",
    "1 = Eligible: The participant had sufficient identifying information to be linked to death records.\n",
    "\n",
    "2 = Under age 18 (not released): The participant was under age 18 and thus not included in the public-use mortality linkage.\n",
    "\n",
    "3 = Ineligible: The participant did not have enough identifying information to perform the mortality linkage.\n",
    "\n",
    "Participants with values 2 or 3 won’t have mortality follow-up data in the public-use file, because they either were too young or lacked required linkage info.\n",
    "\n",
    "2. `MORTSTAT` :This variable indicates the vital status of a participant (whether they are counted as alive or deceased) after linkage to mortality data:\n",
    "\n",
    "0 = Assumed alive: The participant was eligible for linkage and was not found to be deceased in the linked mortality data.\n",
    "\n",
    "1 = Assumed deceased: The participant was eligible and a match to a death record was found.\n",
    "\n",
    "Blank/missing: Not eligible for linkage (e.g., too young or insufficient records).\n",
    "\n",
    "This is typically the main outcome variable used in mortality studies\n",
    "\n",
    "3. `PERMTH_INT`: This variable measures the total number of months the participant was followed for mortality outcomes starting from the survey interview date until:\n",
    "\n",
    "the date of death, if deceased; or\n",
    "\n",
    "the end of the mortality follow-up period (e.g., Dec 31, 2019 for public-use linked data).\n",
    "\n",
    "It provides follow-up time in months (e.g., 0–374 months depending on survey year). If the participant was assumed alive at the end of the follow-up period, this equals the time from interview through that period’s end.\n",
    "\n",
    "4. `RIDAGEEX` : This is an age variable from the underlying survey, specifically:\n",
    "\n",
    "it represents the age of the respondent at the time of their NHANES examination (usually in years).\n",
    "\n",
    "Researchers often use it to define age groups or as a predictor/covariate in mortality analysis (e.g., older vs. younger participants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8d3e59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoking file: (4880, 39)\n",
      "Drug Use file: (2838, 5)\n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "Passing 'suffixes' which cause duplicate columns {'SMQ175_x', 'SMD030_x', 'SMQ145_x', 'SMD160_x', 'SMD100MN_x', 'SMD203_x', 'SMD100NI_x', 'SMD100FL_x', 'SMQ020_x', 'SMD075_x', 'SMQ170_x', 'SMD057_x', 'SMQ210_x', 'SMQ040_x', 'SMD070_x', 'SMD055_x', 'SMQ180_x', 'SMD190_x', 'SMQ205_x', 'SMD100LN_x', 'SMQ140_x', 'SMQ173_x', 'SMD233_x', 'SMD100TR_x', 'SMD080_x', 'SMQ230_x', 'SMD130_x', 'SMD100BR_x', 'SMD100CO_x', 'SMQ050Q_x', 'SMQ050U_x', 'SMQ143_x', 'SMD235_x', 'SMD090_x', 'SMQ150_x', 'SMD220_x', 'SMQ200_x', 'SMQ120_x'} is not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMergeError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m duq = pd.read_sas(\u001b[33m\"\u001b[39m\u001b[33mdata/DUQ.xpt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mxport\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDrug Use file:\u001b[39m\u001b[33m\"\u001b[39m, duq.shape)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSEQN\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m df = df.merge(duq, on=\u001b[33m\"\u001b[39m\u001b[33mSEQN\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFinal merged dataset:\u001b[39m\u001b[33m\"\u001b[39m, df.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rexwa\\anaconda3\\envs\\pysparkenv\\Lib\\site-packages\\pandas\\core\\frame.py:10859\u001b[39m, in \u001b[36mDataFrame.merge\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10840\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m  10841\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m2\u001b[39m)\n\u001b[32m  10842\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m  10855\u001b[39m     validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10856\u001b[39m ) -> DataFrame:\n\u001b[32m  10857\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m> \u001b[39m\u001b[32m10859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10860\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  10861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10862\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10863\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10864\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10865\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10868\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10869\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10870\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10871\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10873\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rexwa\\anaconda3\\envs\\pysparkenv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    170\u001b[39m     op = _MergeOperation(\n\u001b[32m    171\u001b[39m         left_df,\n\u001b[32m    172\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m         validate=validate,\n\u001b[32m    183\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rexwa\\anaconda3\\envs\\pysparkenv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:888\u001b[39m, in \u001b[36m_MergeOperation.get_result\u001b[39m\u001b[34m(self, copy)\u001b[39m\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m.left, \u001b[38;5;28mself\u001b[39m.right = \u001b[38;5;28mself\u001b[39m._indicator_pre_merge(\u001b[38;5;28mself\u001b[39m.left, \u001b[38;5;28mself\u001b[39m.right)\n\u001b[32m    886\u001b[39m join_index, left_indexer, right_indexer = \u001b[38;5;28mself\u001b[39m._get_join_info()\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    891\u001b[39m result = result.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[38;5;28mself\u001b[39m._merge_type)\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.indicator:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rexwa\\anaconda3\\envs\\pysparkenv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:840\u001b[39m, in \u001b[36m_MergeOperation._reindex_and_concat\u001b[39m\u001b[34m(self, join_index, left_indexer, right_indexer, copy)\u001b[39m\n\u001b[32m    837\u001b[39m left = \u001b[38;5;28mself\u001b[39m.left[:]\n\u001b[32m    838\u001b[39m right = \u001b[38;5;28mself\u001b[39m.right[:]\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m llabels, rlabels = \u001b[43m_items_overlap_with_suffix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mright\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuffixes\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[32m    845\u001b[39m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[32m    846\u001b[39m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[32m    847\u001b[39m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[32m    848\u001b[39m     lmgr = left._mgr.reindex_indexer(\n\u001b[32m    849\u001b[39m         join_index,\n\u001b[32m    850\u001b[39m         left_indexer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    855\u001b[39m         use_na_proxy=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    856\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rexwa\\anaconda3\\envs\\pysparkenv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2757\u001b[39m, in \u001b[36m_items_overlap_with_suffix\u001b[39m\u001b[34m(left, right, suffixes)\u001b[39m\n\u001b[32m   2755\u001b[39m     dups.extend(rlabels[(rlabels.duplicated()) & (~right.duplicated())].tolist())\n\u001b[32m   2756\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dups:\n\u001b[32m-> \u001b[39m\u001b[32m2757\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[32m   2758\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPassing \u001b[39m\u001b[33m'\u001b[39m\u001b[33msuffixes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m which cause duplicate columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(dups)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2759\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot allowed.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2760\u001b[39m     )\n\u001b[32m   2762\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m llabels, rlabels\n",
      "\u001b[31mMergeError\u001b[39m: Passing 'suffixes' which cause duplicate columns {'SMQ175_x', 'SMD030_x', 'SMQ145_x', 'SMD160_x', 'SMD100MN_x', 'SMD203_x', 'SMD100NI_x', 'SMD100FL_x', 'SMQ020_x', 'SMD075_x', 'SMQ170_x', 'SMD057_x', 'SMQ210_x', 'SMQ040_x', 'SMD070_x', 'SMD055_x', 'SMQ180_x', 'SMD190_x', 'SMQ205_x', 'SMD100LN_x', 'SMQ140_x', 'SMQ173_x', 'SMD233_x', 'SMD100TR_x', 'SMD080_x', 'SMQ230_x', 'SMD130_x', 'SMD100BR_x', 'SMD100CO_x', 'SMQ050Q_x', 'SMQ050U_x', 'SMQ143_x', 'SMD235_x', 'SMD090_x', 'SMQ150_x', 'SMD220_x', 'SMQ200_x', 'SMQ120_x'} is not allowed."
     ]
    }
   ],
   "source": [
    "smq = pd.read_sas(\"data/SMQ.xpt\", format=\"xport\")\n",
    "print(\"Smoking file:\", smq.shape)\n",
    "\n",
    "duq = pd.read_sas(\"data/DUQ.xpt\", format=\"xport\")\n",
    "print(\"Drug Use file:\", duq.shape)\n",
    "\n",
    "df = df.merge(smq, on=\"SEQN\", how=\"left\")\n",
    "df = df.merge(duq, on=\"SEQN\", how=\"left\")\n",
    "\n",
    "print(\"Final merged dataset:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfd6c3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQN           0\n",
      "SDDSRVYR       0\n",
      "RIDSTATR       0\n",
      "RIDEXMON     683\n",
      "RIAGENDR       0\n",
      "            ... \n",
      "SMD235      9945\n",
      "DUQ100      7360\n",
      "DUQ110      9483\n",
      "DUQ120      9483\n",
      "DUQ130      9914\n",
      "Length: 277, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a67b2d",
   "metadata": {},
   "source": [
    "1. We chose Drug Use and Smoking because we wanted to see how much these impact mortality rates and life expectancy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysparkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
